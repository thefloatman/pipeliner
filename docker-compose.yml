version: '3.8'

services:
  postgres:
    image: postgres:9.6
    environment:
      - POSTGRES_USER=${AIRFLOW}
      - POSTGRES_PASSWORD=${AIRFLOW}
      - POSTGRES_DB=${AIRFLOW}
    logging:
      options:
          max-size: 10m
          max-file: "3"

  airflow:
    container_name: airflow
    build: ./airflow
    restart: unless-stopped
    logging:
      options:
        max-size: 10m
        max-file: "3"
    command: ["webserver"]
    ports:
      - 8080:8080
    volumes:
      - ./airflow/dags:/usr/local/airflow/dags
      - ./airflow/modules:/usr/local/airflow/modules
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
    depends_on:
      - postgres

  kafka:
    container_name: kafka
    build: ./kafka
    ports:
     - "9092:9092"
    expose:
     - "9093"
    environment:
      - KAFKA_ADVERTISED_LISTENERS=${KAFKA_ADVERTISED_LISTENERS}
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP}
      - KAFKA_LISTENERS=${KAFKA_LISTENERS}
      - KAFKA_INTER_BROKER_LISTENER_NAME=${KAFKA_INTER_BROKER_LISTENER_NAME}
      - KAFKA_ZOOKEEPER_CONNECT=${KAFKA_ZOOKEEPER_CONNECT}
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=${KAFKA_AUTO_CREATE_TOPICS_ENABLE}
    depends_on:
        - zookeeper

  kafdrop:
    image: obsidiandynamics/kafdrop
    restart: "no"
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:9093"
      JVM_OPTS: "-Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify"
    depends_on:
      - "kafka"

  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:5.3.1
    environment:
        - ZOOKEEPER_CLIENT_PORT=${ZOOKEEPER_CLIENT_PORT}
    ports:
        - 2181:2181

  mongo:
    container_name: mongo
    image: mongo:4.2
    command: ["mongod", "--replSet", "rs0", "--auth"]
    environment: 
        - MONGO_ADMIN=${MONGO_ADMIN}
        - MONGO_DB_NAME=${MONGO_DB_NAME}
    ports:
        - 27017:27017
    volumes:
        - ./mongo/init.sh:/usr/local/bin/init.sh

  kafka-connect:
    container_name: connect
    build: ./connect
    environment:
        - CONNECT_REST_ADVERTISED_HOST_NAME=${CONNECT_REST_ADVERTISED_HOST_NAME}
        - CONNECT_SCHEMA_REGISTRY_URL=${SCHEMA_REGISTRY_URL}
        - CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL=${SCHEMA_REGISTRY_URL}
        - CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL=${SCHEMA_REGISTRY_URL}
        - CONNECT_BOOTSTRAP_SERVERS=${CONNECT_BOOTSTRAP_SERVERS} 
    ports:
        - 8083:8083
    depends_on:
        - kafka
        - schema-registry

  elasticsearch:
    container_name: elasticsearch
    build: ./elasticsearch
    restart: unless-stopped
    ulimits:
        memlock:
            soft: -1
            hard: -1
    ports:
        - 9200:9200

  kibana:
    container_name: kibana
    image: docker.elastic.co/kibana/kibana:7.7.0
    volumes:
      - ./kibana/kibana.yml:/usr/share/kibana/config/kibana.yml
    ports:
        - 5601:5601
    depends_on:
        - elasticsearch
    restart: on-failure

  schema-registry:
    container_name: schema-registry
    image: confluentinc/cp-schema-registry:5.3.1
    environment:
        - SCHEMA_REGISTRY_HOST_NAME=${SCHEMA_REGISTRY_HOST_NAME}
        - SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL=${SCHEMA_REGISTRY_LOGLEVEL}
        - SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=${SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS}
    depends_on:
        - kafka  

networks:
  default:
    name: pipeliner-network

volumes:
    static_data: {}